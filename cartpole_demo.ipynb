{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32634ceb",
   "metadata": {},
   "source": [
    "# CartPole Evolution Demo\n",
    "\n",
    "This notebook demonstrates how to evolve Linear Genetic Programming (LGP) individuals to balance the CartPole environment using the utilities in this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b259233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "from memory_system import MemoryConfig, MemoryBank\n",
    "from instruction_set import InstructionSet\n",
    "from operation import ALL_OPS, SCALAR_OPS\n",
    "from individual import Individual\n",
    "from population import Population, PopulationConfig\n",
    "from operators import GeneticOperators\n",
    "from evaluator import CartPoleEvaluator\n",
    "from evolution_engine import EvolutionEngine, EvolutionConfig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f6c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "\n",
    "memory_cfg = MemoryConfig(\n",
    "    n_scalar=8,\n",
    "    n_vector=0,\n",
    "    n_matrix=0,\n",
    "    n_obs_scalar=4,\n",
    "    n_obs_vector=0,\n",
    "    n_obs_matrix=0,\n",
    "    vector_size=1,\n",
    "    matrix_shape=(1, 1),\n",
    ")\n",
    "\n",
    "# Use only scalar operations for CartPole (actions derived from scalar register)\n",
    "instruction_set = InstructionSet([op() for op in SCALAR_OPS], memory_cfg)\n",
    "operators = GeneticOperators(instruction_set, rng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44c63d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_config = PopulationConfig(size=30, program_length=(6, 12), elitism=2, max_program_length=20)\n",
    "population = Population(population_config, instruction_set, memory_cfg, operators=operators, rng=rng)\n",
    "population.initialize_random(mutate_constants=True)\n",
    "\n",
    "cartpole_eval = CartPoleEvaluator(episodes=5, max_steps=500, output_register=7, rng=rng)\n",
    "engine = EvolutionEngine(\n",
    "    population=population,\n",
    "    operators=operators,\n",
    "    evaluator=cartpole_eval,\n",
    "    config=EvolutionConfig(max_generations=10, mutation_threshold=0.2, constant_mutation_rate=0.2, verbose=False),\n",
    "    rng=rng,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515114fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Generation 10 | Population size 30\n",
      "Min: 500.000, Mean: 500.000, Max: 500.000, Std: 0.000\n",
      "Length mean 10.9, std 2.0\n",
      "Best ever fitness 500.000 at generation 5\n",
      "============================================================\n",
      "Best fitness: 500.0\n"
     ]
    }
   ],
   "source": [
    "final_population = engine.run()\n",
    "final_population.print_summary()\n",
    "\n",
    "best_individual = final_population.best_ever\n",
    "print(\"Best fitness:\", best_individual.fitness)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40cea0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(individual: Individual, render_mode: str = \"rgb_array\"):\n",
    "    env = gym.make(\"CartPole-v1\", render_mode=render_mode)\n",
    "    observation, _ = env.reset()\n",
    "    observation = np.asarray(observation, dtype=np.float32)\n",
    "    memory = individual.memory.copy()\n",
    "    frames = []\n",
    "    total_reward = 0.0\n",
    "    for _ in range(500):\n",
    "        memory.load_observation({'scalar': observation.tolist()})\n",
    "        individual.program.execute(memory)\n",
    "        action_value = memory.read_scalar(7)\n",
    "        action = 1 if action_value >= 0.0 else 0\n",
    "        observation, reward, terminated, truncated, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        observation = np.asarray(observation, dtype=np.float32)\n",
    "        if render_mode == \"rgb_array\":\n",
    "            frame = env.render()\n",
    "            frames.append(frame)\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    env.close()\n",
    "    return total_reward, frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ae58a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "reward, frames = run_episode(best_individual, render_mode=\"human\")\n",
    "print(f\"Episode reward: {reward}\")\n",
    "\n",
    "if frames:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(frames[0])\n",
    "    plt.title(\"First frame of best policy\")\n",
    "    plt.axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80872816",
   "metadata": {},
   "source": [
    "> Tip: set `render_mode=\"human\"` inside `run_episode` to watch the agent live (requires a display).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LGP_VISION",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
